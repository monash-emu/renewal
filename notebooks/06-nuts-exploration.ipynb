{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Renewal model fitting\"\n",
    "format: \n",
    "  pdf\n",
    "execute:\n",
    "  echo: false\n",
    "jupyter: python3\n",
    "bibliography: renew.bib\n",
    "csl: https://www.zotero.org/styles/the-lancet\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to install on Colab or similar\n",
    "#! pip install git+https://github.com/monash-emu/wpro-working.git@more-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "from jax import jit, random\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "import arviz as az\n",
    "from IPython.display import Markdown\n",
    "from plotly.express.colors import qualitative as qual_colours\n",
    "import numpy as np\n",
    "\n",
    "from estival.sampling import tools as esamp\n",
    "\n",
    "from emu_renewal.process import CosineMultiCurve\n",
    "from emu_renewal.distributions import GammaDens\n",
    "from emu_renewal.renew import RenewalModel\n",
    "from emu_renewal.outputs import get_spaghetti_from_params, get_quant_df_from_spaghetti, plot_spaghetti, plot_uncertainty_patches, PANEL_SUBTITLES, plot_3d_spaghetti\n",
    "from emu_renewal.calibration import StandardCalib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify fixed parameters and get calibration data\n",
    "proc_update_freq = 14\n",
    "init_time = 50\n",
    "mys_data = pd.read_csv(\"https://github.com/monash-emu/wpro_working/raw/main/data/new_cases.csv\", index_col=0)[\"MYS\"]\n",
    "mys_data.index = pd.to_datetime(mys_data.index)\n",
    "pop = 33e6\n",
    "analysis_start = datetime(2021, 3, 1)\n",
    "analysis_end = datetime(2021, 11, 1)\n",
    "init_start = analysis_start - timedelta(init_time)\n",
    "init_end = analysis_start - timedelta(1)\n",
    "select_data = mys_data.loc[analysis_start: analysis_end]\n",
    "init_data = mys_data.loc[init_start: init_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = CosineMultiCurve()\n",
    "renew_model = RenewalModel(33e6, analysis_start, analysis_end, proc_update_freq, fitter, GammaDens(), 50, init_data, GammaDens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter ranges\n",
    "priors = {\n",
    "    \"gen_mean\": dist.Gamma(10.0, 1.0),\n",
    "    \"gen_sd\": dist.Gamma(5.0, 1.0),\n",
    "    \"cdr\": dist.Beta(4.0, 10.0),\n",
    "    \"rt_init\": dist.Normal(0.0, 0.25),\n",
    "    \"report_mean\": dist.Uniform(8.0, 12.0),\n",
    "    \"report_sd\": dist.Uniform(3.0, 6.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = StandardCalib(renew_model, priors, mys_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function for PDF of a prior\n",
    "def plotpdf(p):\n",
    "    x = np.linspace(p.icdf(0.001),p.icdf(0.999),100)\n",
    "    return pd.Series(data=np.exp(p.log_prob(x)),index=x)\n",
    "\n",
    "plotpdf(priors[\"cdr\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a random uniform sampling of initial points, but constrain the radius of the sample to lower\n",
    "# than default; because our random process covers a lot of parameter space, we don't want to sample too far out,\n",
    "# but still want to retain more diversity than simply using the median for all chains\n",
    "kernel = numpyro.infer.NUTS(calib.calibration, dense_mass=True, init_strategy=infer.init_to_uniform(radius=0.5))\n",
    "\n",
    "# We can start with any values we want for num_samples and num_warmup here\n",
    "# 1000,1000 should be enough 'most of the time', and is useful while testing - expect a few bad runs depending on the seed\n",
    "# 2000,2000 should be considerably more robust\n",
    "# Higher values may be required for exacting results with 'pristine' r values\n",
    "mcmc = numpyro.infer.MCMC(kernel, num_chains=2, num_samples=1000, num_warmup=1000)\n",
    "rng_key = random.PRNGKey(14)\n",
    "#mcmc.run(rng_key, extra_fields=(\"accept_prob\",\"diverging\"), params=priors,collect_warmup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the warmup phase of the mcmc separately - we want to examine this behaviour before committing to a run\n",
    "# Things we're looking for - all chains run at approximately the same speed as one another\n",
    "# (eg no order of magnitude differences)\n",
    "# It's normal for runs to speed up during the warmup (as they get closer to the viable region)\n",
    "\n",
    "mcmc.warmup(rng_key, extra_fields=(\"accept_prob\", \"diverging\", \"potential_energy\"), params=priors, collect_warmup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the potential energy (equivalent to log density) of our warmup samples\n",
    "# By the end of the warmup run, these should be all in the same range for every chain\n",
    "# If they are not, then there is no point running a calibration - either we've\n",
    "# got a bad initial point (shouldn't happen), or something is wrong with our model/priors/NUTS configuration\n",
    "# Even if they end up in the same place, it is worth checking to see if some chains took unusually long to \n",
    "# converge - if so, they could cause issues with the mass matrix calculation used for the actual calibration\n",
    "# sampling.  Longer warmups should resolve this.\n",
    "\n",
    "# Don't worry if chains occasionally dip lower than the others - this is a more 'perfect fit'/better MAP estimate\n",
    "# but outside the center of mass - as long as they come back to the same range for most of the trace, all is well\n",
    "\n",
    "pd.DataFrame(mcmc.get_extra_fields(True)[\"potential_energy\"]).T.iloc[-1000:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the actual MCMC\n",
    "# This should sample a bit faster than the warmup (if everything went right as above, then all our chains are properly\n",
    "# preconditioned)\n",
    "\n",
    "# If there are any chains running considerably faster or slower than the others, then something is wrong\n",
    "# (most likely the mass matrix tuning is different for this chain; you can check the potential energy/trace\n",
    "# to validate this)\n",
    "\n",
    "mcmc.run(rng_key, extra_fields=(\"accept_prob\",\"diverging\",\"potential_energy\"), params=priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = az.from_numpyro(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be an absolute maximum of 1.05 for any actual inference (good enough to \n",
    "# not be misleading, but still not really appropriate for publication/policy advice)\n",
    "# For this kind of model, 1.00 is the target\n",
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 0\n",
    "n_samples = 200\n",
    "quantiles = [0.05, 0.5, 0.95]\n",
    "idata_burnt = idata.sel(draw=slice(burn_in, None))\n",
    "idata_sampled = az.extract(idata_burnt, num_samples=n_samples)\n",
    "sample_params = esamp.xarray_to_sampleiterator(idata_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_result(gen_mean, gen_sd, proc, cdr, rt_init, report_mean, report_sd):\n",
    "    return renew_model.renewal_func(gen_mean, gen_sd, proc, cdr, rt_init, report_mean, report_sd)\n",
    "\n",
    "full_wrap = jit(get_full_result)\n",
    "spaghetti = get_spaghetti_from_params(renew_model, sample_params, full_wrap)\n",
    "quantiles_df = get_quant_df_from_spaghetti(renew_model, spaghetti, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_fig = plot_uncertainty_patches(quantiles_df, select_data, qual_colours.Plotly)\n",
    "patch_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(renew_model.get_description())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_spaghetti(spaghetti, select_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - requires kaleido\n",
    "#| label: fig-calib\n",
    "#| fig-cap: \"Calibration to sample data from Malaysia\"\n",
    "# patch_fig.write_image(\"patch_fig.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_df.columns = [\"name\", \"Lower limit\", \"Upper limit\"]\n",
    "# params_df.index = params_df[\"name\"]\n",
    "# params_df = params_df.drop(columns=[\"name\"])\n",
    "# params_df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\"### Calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(calib.get_description())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown(params_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidence_table = pd.DataFrame(index=params_df.index, columns=[\"Evidence\"])\n",
    "# evidence_table.loc[:, \"Evidence\"] = \"To be populated [@cori2013]\"\n",
    "# Markdown(evidence_table.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_3d_spaghetti(spaghetti, [\"susceptibles\", \"transmission potential\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
